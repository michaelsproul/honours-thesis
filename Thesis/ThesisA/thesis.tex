\documentclass[]{unswthesis}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{enumerate}
\usepackage{amsmath, amssymb}
\usepackage{mathtools}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{multicol}
\usepackage[nottoc,numbib]{tocbibind}
\usepackage{proof}
% \usepackage[scale=2]{ccicons}

% Disable hideous fluorescent links
\hypersetup{hidelinks=true}

%%% Class options:

%  undergrad (default)
%  hdr

%  11pt (default)
%  12pt

%  final (default)
%  draft

%  oneside (default for hdr)
%  twoside (default for undergrad)


%% Thesis details
\thesistitle{Computer-verified proof of type soundness for the Linear Language with Locations, $L^3$}
\thesisschool{School of Computer Science and Engineering}
\thesisauthor{Michael Alexander Sproul}
\thesisZid{z3484357}
\thesistopic{} % TODO: Find out what this is meant to be?
\thesisdegree{Bachelor of Science (Honours)}
\thesisdate{October 2015}
\thesissupervisor{Dr. Ben Lippmeier}

%% My own LaTeX macros, definitions, etc.
\let\oldemptyset\emptyset
\let\emptyset\varnothing
\newcommand{\case}{\text{ case }}
\newcommand{\of}{\text{of }}
\newcommand{\yields}{\multimap}
\newcommand{\steps}{\Rightarrow}
\newcommand{\lquine}{\left\ulcorner}
\newcommand{\rquine}{\right\urcorner}
\newcommand{\capa}{\text{cap}}
\newcommand{\ptr}{\text{ptr }}

\begin{document}

%% pages in the ``frontmatter'' section have roman numeral page number
\frontmatter  
\maketitle

% \include{abstract}
% \include{acknowledgements}
% Do I need these?
% \include{abbreviations}

\tableofcontents
%\listoffigures
%\listoftables

%% pages in the ``mainmatter'' section have arabic page numbers and chapters are numbered
\mainmatter

% \include{introduction}
\chapter{Introduction}
\label{ch:intro}

Computer systems form an integral part of modern society, both in the form of personal devices and critical infrastructure. Ensuring the correct operation of computer hardware and software is therefore required. One emerging technique for the construction of robust software systems is the use of mathematical formalisations and proofs of correctness. In this paradigm, desirable properties of the software can be proven true using a computer-based \textit{proof assistant}, which itself relies only on a minimal amount of trusted code. For software formalisation and verification to be truly effective, the objects under consideration must have precise mathematical models associated with them. Typically these models are created based on the \textit{semantics} (meaning) of the programming language that the software is written in. Unfortunately for the would-be software verifier, most popular programming languages lack formal semantics and are therefore not amenable to verification techniques. The focus of this thesis is the computer-based formalisation of language semantics for a specific language (\textit{The Linear Language with Locations} -- $L^3$), as a pre-requisite for further verification of software written in this language.

\section{Operational Semantics}

\section{Type Systems and Type Safety}

\section{Logic, Type Theory and the Coq proof assistant}

\section{Verification Aims}

The $L^3$ language was specified in a 2001 (2005? 2007?) paper by Ahmed et al (REF). The paper includes a hand-written proof of type soundness for $L^3$ core, spanning 8 pages.

Include motivation for linear/uniqueness typing here.

% Background.
\chapter{Background}
\label{ch:intro}

% Overall picture (verified all the way down, focus on low-level languages).
% Focus on "normal" semantics and type systems.
% Notes about TAL

If software verification is to propagate through modern software stacks, verification of components at different layers is a necessity. Proofs about programs written in high-level languages offer only superficial assurances if during compilation down to executable machine code* the program is corrupted by an unverified transformation. Verification of entire computing systems including compilers, operating systems and file-systems is a huge undertaking however, so we restrict our attention here to the type systems of low-level languages.

Historically, low-level \textit{systems software} has been written primarily in the C programming language, which was originally designed without a formal semantics. Attempts to assign semantics to C have been quite successful, and have resulted in numerous impressive verification projects -- notably the CompCert verified compiler (REF) and the seL4 micro-kernel (REF). In this work we consider type systems for languages that could potentially act as verification-friendly successors to the domains where C currently excels (operating systems, language runtimes, embedded devices). Our core hypothesis is that \textit{uniqueness types} and the destructive updates they enable should simplify the verification of systems software.

% FIXME: make this a footnote.
*We don't consider other methods of computation in the present paper, e.g. logic gates and qubits.

\section{Previous Work}

\subsection{Linear and Affine Typing}

Linear, affine and uniqueness typing are closely-related features of type systems that enforce rules about the number of times values may be used and referenced. These restrictions are motivated by several desirable features that can be obtained by enforcing them. The Clean programming language (REF) uses uniqueness typing to ensure that values in memory have at most one reference to them, thus enabling \textit{destructive updates} whilst preserving referential transparency. The Rust programming language (REF) uses uniqueness typing to track and free heap-allocated memory, thus allowing it to achieve memory safety without garbage collection. This makes it suitable for writing systems software where a garbage collector isn't available (like a garbage collector itself, or an operating system).

Linear and affine type systems are based on linear and affine logic respectively (REF Girard and Grishin), via the standard mapping from logic to type systems (see previous section?). In classical and intuitionistic logic there are deduction rules equivalent to the following, called \textit{Contraction} and \textit{Weakening}.

\begin{eqnarray*}
\infer[\text{Contraction}]{\Gamma, A \vdash B}{
	\Gamma, A, A \vdash B
}
\qquad
\infer[\text{Weakening}]{\Gamma, A \vdash B}{
    \Gamma \vdash B
}
\end{eqnarray*}

Contraction allows duplicate assumptions to be discarded, whilst Weakening allows a non-vital extra assumption to be introduced from nowhere. Linear logic bans the use of both rules, such that every assumption is used \textit{exactly once}. Affine logic on the other hand bans only the use of Contraction, which results in the requirement that every assumption be used \textit{at most once}. When transformed into typing rules, Contraction and Weakening take the form:

\begin{eqnarray*}
\infer[\text{Contraction}]{\Gamma, x : A \vdash u[x/y, x/z] :: B}{
	\Gamma, y : A, z : A \vdash u :: B
}
\qquad
\infer[\text{Weakening}]{\Gamma, x : A \vdash y :: B}{
    \Gamma\vdash y :: B
}
\end{eqnarray*}

(Note that the use of substitutions in the rule for Contraction is required so that no variable appears more than once in a typing context $\Gamma$).

As in linear and affine logic, linear type theory prevents the use of Contraction and Weakening, whilst affine type theory prevents just the use of Contraction. Our previous observations about the number of times an assumption is used now translate into observations about the number of times variables are used.

Without Contraction, \textit{variables can only appear once in a term}. The dual substitution of $x$ for $y$ and $x$ for $z$ allows a term containing one $y$ and one $z$ to become a term containing two occurrences of $x$. None of the other rules of intuitionistic type theory allow this (REF Wadler).

Similarly, without Weakening, \textit{all variables in the context must be used in the term}. This follows from the fact that Weakening introduces an unused variable to the context and no other rule of intuitionistic type theory allows this.

From these two observations we can conclude that linear type theory requires all variables to be used \textit{exactly once} in terms, whilst affine type theory requires all variables to be used \textit{at most once} in terms.

It's also worth noting that linear and affine type theory don't entirely ban Contraction and Weakening -- their use is allowed for certain \textit{non-linear} values and types. This is quite practical in the context of programming language implementation as it allows trivially copyable values like integers to be easily duplicated. The mechanism employed by Wadler to selectively allow Contraction and Weakening involves differentiating between linear and non-linear assumptions, and adding type and value-level bang (!) operators to make types and values non-linear. The function for duplication of non-linear values (of type $!A$) is expressed as follows in such a system :

\begin{eqnarray*}
\varnothing \vdash \lambda \langle x' \rangle . \case x' \of !x \rightarrow \langle !x, !x\rangle :\text{ } !A \yields (!A \otimes !A)
\end{eqnarray*}

See Wadler 1993 for full notational details.

\subsection{Uniqueness Typing}

Although linear and affine type theory capture the essence of uniquely referenced values, they are insufficient to describe the concept of \textit{uniqueness} as it appears in languages like Clean. In his 2008 paper, de Vries (REF) notes that terms of a unique type are \textit{guaranteed to never have been shared}, which is sufficient to guarantee a unique pointer at runtime. In contrast, terms of linear (or affine) type are \textit{guaranteed not to be shared in the future}, which is insufficient to guarantee a unique pointer.

Without implying equivalence of the two concepts, let $\alpha^\bullet$ denote the type of both linear and unique values, for any base type $\alpha$ (such as \texttt{Int}). Similarly, allow the notation $\alpha^\times$ to stand for non-linear and non-unique types.

\begin{eqnarray*}
\lambda x \cdot x : & \alpha^\times \rightarrow \alpha^\bullet & \text{(linear dereliction)}\\
\lambda x \cdot x : & \alpha^\bullet \rightarrow \alpha^\times & \text{(uniqueness removal)}
\end{eqnarray*}

The distinctness of linearity and uniqueness is further highlighted by the \textit{dereliction} rule present in some versions of linear type theory, and the rule that we'll refer to as \textit{uniqueness removal} present in Clean's type system. As noted by de Vries (REF de Vries PhD thesis), the presence of the dereliction rule allows a non-linear value to be transformed into a linear one, thus breaking any alleged equivalence of linearity and uniqueness (by definition, a non-unique value should not suddenly become unique). Conversely, intuition about uniqueness suggests that treating a unique value as non-unique should be allowed - hence, uniqueness removal.

Note that dereliction need not form a part of type systems based on linear logic, and that it is absent from Wadler's presentations (REF 1991, 1993). Further note that if uniqueness is to be exploited to make garbage collection unnecessary -- as in the case of Rust -- then the uniqueness removal rule is undesirable as it prevents values from having a unique owner.

Due to the non-equivalence of linearity and uniqueness, de Vries constructed a distinct set of semantics and typing rules to model Clean's type system (REF de Vries).

One key component of his approach is the use of the \textit{kind} (type of types) system to track uniqueness and non-uniqueness. As in Haskell, de Vries' uniqueness system includes a kind for data (\texttt{*}) which is the kind of all inhabited types. In addition, there is a uniqueness kind $\mathcal{U}$ inhabited by two types $\bullet$ and $\times$ representing uniqueness and non-uniqueness respectively. A third kind, $\mathcal{T}$ is the kind of base types (like \texttt{Int}). These kinds are brought together by a type constructor $\texttt{Attr} ::_k \mathcal{T} \rightarrow \mathcal{U} \rightarrow *$ which applies a uniqueness attribute to a base type to form a type that is inhabited (e.g. \texttt{Attr} $\bullet$ \texttt{Int} or $\texttt{Int}^\bullet$ for the type of uniquely referenced integers).

The other main technique employed by de Vries' model is the use of arbitrary boolean expressions as uniqueness attributes, with $\bullet$ as true and $\times$ as false. Clean's type system allows uniqueness polymorphism, which results in constraint relationships between uniqueness variables, which are represented in de Vries system as simple boolean expressions that can be handled by a standard unification algorithm. FIXME: Does this need to be here?

Importantly, de Vries work includes the only known mechanical verification of a type system similar to Clean's. The formalisation uses the Coq proof assistant, and the \textit{locally nameless} (REF) approach to variable naming that will be discussed in (FIXME: SOME SECTION).

% Linear + affine logic and control over contraction and weakening. DONE.

% Uniqueness typing as an alternative (mention dereliction, non guarantees). DONE.

% de Vries formalisation of Clean's uniqueness typing using attributes.

\subsection{Systems of Capabilities}

% rgnURAL as a basis for Cyclone.

% Francois Pottier's low-level thing.

% Mezzo. Strong updates, etc.

\subsection{Trust-worthy compilers, typed assembly languages and other similar systems}

\section{The Linear Language with Locations, $L^3$}

\chapter{Proposal}

\section{Variable naming and binding}

One problem that arises frequently in the formalisation of language semantics is that of \textit{capture-avoiding substitution}. Substitution operations, whereby a value is substituted for a variable in a term, form the core computational component of the operational semantics in many languages. In the simply-typed (and untyped) lambda calculus, the $\beta$-rule uses substitution (denoted $e[v/x]$) to describe the semantics of function application:
% FIXME: formatting, long right arrow and space.
\begin{eqnarray*}
(\lambda x : \tau. e) v \Rightarrow_\beta e[v/x]
\end{eqnarray*}

The problem of \textit{variable capture}, which we wish to avoid, is demonstrated by the following example:
% FIXME: formatting
\begin{eqnarray*}
(\lambda x. \lambda y. x + y) y \Rightarrow_\beta (\lambda y. y + y)
\end{eqnarray*}

Here the parameter $y$ is a free variable acting as a place-holder for a value in the environment. After substitution however, the $y$ replacing $x$ in the abstraction body $x + y$ becomes bound due to the name collision between the free $y$ and the binder $y$. Intuitively, drastically altering the meaning of terms during substitution is something we would like to avoid.

One way to avoid variable capture is to forbid the substitution of any terms containing free variables. In such a system, free variables like $y$ are never considered values and as such cannot be used in (variable capturing) substitutions. This is the approach taken by \textit{Software Foundations} (REF) in formalisations of the simply-typed lambda calculus and its variants. A further consequence of this approach is that globally-shared integers or strings for variable names are sufficient to guarantee soundness. Although it's tempting to embrace this approach for its simplifying properties, it doesn't accurately capture the behaviour of common functional languages like Haskell and ML, which perform substitutions whilst avoiding variable capture. (might need a stronger argument here).

In our Coq formalisation of $L^3$ we would therefore like to include \textit{capture avoiding substitution} as part of the definitions of variable names and substitution operations. For this we consider three main approaches from the literature which all exploit the observation that the exact names of bound variables are insignificant at the level of language formalisation. In other words, although the names of variables may hold meaning for the authors of programs, they do not impact the meaning of the programs themselves.

\subsection{Higher-order Abstract Syntax}

\subsection{de Bruijn indices}

\subsection{The Locally Nameless approach}



%\include{background}
%\include{proposal}
%\include{mywork}
%\include{evaluation}
%\include{conclusion}

%% chapters in the ``backmatter'' section do not have chapter numbering
%% text in the ``backmatter'' is single spaced
\backmatter
\bibliographystyle{alpha}
\bibliography{pubs}

%\include{appendix1}
%\include{appendix2}

\end{document}
